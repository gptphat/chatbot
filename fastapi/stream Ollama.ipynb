{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOiNh79llOPs4xK55b8DubU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"np3F2nAhCymq","executionInfo":{"status":"ok","timestamp":1705768185581,"user_tz":-420,"elapsed":12249,"user":{"displayName":"Hùng Nguyễn","userId":"13177030219094617255"}}},"outputs":[],"source":["!pip install --upgrade gdown litellm fastapi nest-asyncio uvicorn async_generator pycloudflared &> /dev/null"]},{"cell_type":"code","source":["!curl https://ollama.ai/install.sh | sh &> /dev/null"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M3stm1N7C1Jm","outputId":"56bb692f-9c9a-4b2d-e6e1-f3dc4bf605fe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100  8422    0  8422    0     0  21785      0 --:--:-- --:--:-- --:--:-- 21818\n"]}]},{"cell_type":"code","source":["!gdown https://drive.google.com/drive/folders/1OqHpLJ3vttta1wZQcopLP18Eb05f5f2I -O ./folder --folder &> /dev/null"],"metadata":{"id":"X9p2ZIX_Fh3L","executionInfo":{"status":"ok","timestamp":1705768185581,"user_tz":-420,"elapsed":27,"user":{"displayName":"Hùng Nguyễn","userId":"13177030219094617255"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["!nohup ollama serve &"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bB5W9T4tOqo-","executionInfo":{"status":"ok","timestamp":1705768185581,"user_tz":-420,"elapsed":26,"user":{"displayName":"Hùng Nguyễn","userId":"13177030219094617255"}},"outputId":"6637498b-181d-4c2e-f971-7e33f3cbb7c8"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["nohup: appending output to 'nohup.out'\n"]}]},{"cell_type":"code","source":["!ollama create PhatGPT -f ./folder/Modelfile &> /dev/null"],"metadata":{"id":"GkgRzYbQGoDj","executionInfo":{"status":"ok","timestamp":1705768256469,"user_tz":-420,"elapsed":70910,"user":{"displayName":"Hùng Nguyễn","userId":"13177030219094617255"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["from fastapi import FastAPI\n","from fastapi.responses import StreamingResponse\n","from fastapi.middleware.cors import CORSMiddleware\n","from litellm import acompletion\n","from pydantic import BaseModel\n","from typing import List\n","import json\n","import aiohttp\n","\n","class RequestModel(BaseModel):\n","    model: str\n","    messages: List[dict]\n","    stream: bool\n","\n","app = FastAPI()\n","\n","app.add_middleware(\n","    CORSMiddleware,\n","    allow_origins=['*'],\n","    allow_credentials=True,\n","    allow_methods=['*'],\n","    allow_headers=['*'],\n",")\n","\n","host_ollama = \"http://127.0.0.1:11434\"\n","\n","async def get_json_events(request: RequestModel):\n","  response = await acompletion(\n","      model=f\"ollama/{request.model}\",\n","      messages=request.messages,\n","      api_base=host_ollama,\n","      max_tokens=1024,\n","      stream=request.stream\n","  )\n","  async for chunk in response:\n","    if chunk['choices'][0]['finish_reason']:\n","      break\n","    yield chunk['choices'][0]['delta'][\"content\"]\n","\n","@app.post(\"/api/chat\", response_class=StreamingResponse)\n","async def chat(request: RequestModel):\n","  return StreamingResponse(get_json_events(request))\n","\n","@app.get(\"/api/tags\")\n","async def tags():\n","  async with aiohttp.ClientSession() as session:\n","    async with session.get(f\"{host_ollama}/api/tags\") as resp:\n","      return await resp.json()\n","\n","# if __name__ == '__main__':\n","#     uvicorn.run(app, port=8080, host='0.0.0.0', workers=1, debug=True)"],"metadata":{"id":"OjuOABhvApAD","executionInfo":{"status":"ok","timestamp":1705768258588,"user_tz":-420,"elapsed":2127,"user":{"displayName":"Hùng Nguyễn","userId":"13177030219094617255"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["import asyncio\n","from uvicorn import Config, Server\n","\n","config = Config(app)\n","server = Server(config=config)\n","loop = asyncio.get_event_loop()\n","loop.create_task(server.serve())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ITDLvoZ3rMQn","executionInfo":{"status":"ok","timestamp":1705768259041,"user_tz":-420,"elapsed":461,"user":{"displayName":"Hùng Nguyễn","userId":"13177030219094617255"}},"outputId":"61c7322b-1f91-42eb-e845-2452ef6501b1"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<Task pending name='Task-1' coro=<Server.serve() running at /usr/local/lib/python3.10/dist-packages/uvicorn/server.py:64>>"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["import subprocess\n","import threading\n","import re\n","\n","process = subprocess.Popen(['pycloudflared', 'tunnel', '--url', 'http://127.0.0.1:8000'],\n","                            stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n","\n","for line in iter(process.stdout.readline, ''):\n","    if '.trycloudflare.com' in line:\n","        url = re.search(r'https://[a-zA-Z0-9-]+\\.trycloudflare\\.com', line)\n","        if url:\n","            print(f\"Tunnel URL: {url.group()}\")\n","            break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tDUL-0v2pnzV","executionInfo":{"status":"ok","timestamp":1705768260418,"user_tz":-420,"elapsed":1381,"user":{"displayName":"Hùng Nguyễn","userId":"13177030219094617255"}},"outputId":"d34983f2-d6f5-48e6-e3f4-c1df4eaf4915"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Tunnel URL: https://yacht-specialty-everywhere-sandra.trycloudflare.com\n"]},{"output_type":"stream","name":"stderr","text":["INFO:     Started server process [16013]\n","INFO:     Waiting for application startup.\n"]}]},{"cell_type":"code","source":["# import nest_asyncio\n","\n","# nest_asyncio.apply()\n","\n","# import uvicorn\n","\n","# uvicorn.run(app)"],"metadata":{"id":"VdArbnVojAe_","executionInfo":{"status":"ok","timestamp":1705768260419,"user_tz":-420,"elapsed":19,"user":{"displayName":"Hùng Nguyễn","userId":"13177030219094617255"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["url.group()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"1PxW-gfeREnc","executionInfo":{"status":"ok","timestamp":1705768260419,"user_tz":-420,"elapsed":18,"user":{"displayName":"Hùng Nguyễn","userId":"13177030219094617255"}},"outputId":"ce109cab-8c52-47ca-e4bf-440be3ed86ea"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'https://yacht-specialty-everywhere-sandra.trycloudflare.com'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":[],"metadata":{"id":"Xyeyy2LnswF4","executionInfo":{"status":"aborted","timestamp":1705768260420,"user_tz":-420,"elapsed":15,"user":{"displayName":"Hùng Nguyễn","userId":"13177030219094617255"}}},"execution_count":null,"outputs":[]}]}